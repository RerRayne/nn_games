{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multy Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load MNIST or read the downloaded version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.examples.tutorials.mnist import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "INPUT_DATA_DIR = '/tmp/tensorflow/mnist/input_data'\n",
    "data_sets = input_data.read_data_sets(INPUT_DATA_DIR, one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the placeholders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "FEATURES_NUM = mnist.IMAGE_PIXELS\n",
    "CLASSES_NUM = mnist.NUM_CLASSES\n",
    "with tf.variable_scope(\"dataset\"):\n",
    "    x = tf.placeholder(tf.float32, shape=(BATCH_SIZE, FEATURES_NUM), name='features')\n",
    "    y = tf.placeholder(tf.float32, shape=(BATCH_SIZE, CLASSES_NUM), name='labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the initializer for weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weight(shape, stddev=0.1, name=None):\n",
    "    init = tf.truncated_normal(shape, stddev=stddev)\n",
    "    return tf.Variable(init, name=name)\n",
    "\n",
    "def init_bias(shape, def_value = 0.1, name=None):\n",
    "    init = tf.constant(def_value, shape=shape)\n",
    "    return tf.Variable(init, name=name)\n",
    "\n",
    "def build_mlp_layer(input_shape, output_shape, scope_name, stddev=0.1, def_value=0.1):\n",
    "    with tf.name_scope(scope_name):\n",
    "        weight = init_weight((input_shape, output_shape), stddev=stddev, name=\"weights\")\n",
    "        bias = init_bias((output_shape,), def_value=def_value, name=\"bias\")\n",
    "        return weight, bias, scope_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_FEATURES_1 = 256\n",
    "HIDDEN_FEATURES_2 = 256\n",
    "\n",
    "layers = [build_mlp_layer(input_shape, output_shape, scope_name) \\\n",
    "          for input_shape, output_shape, scope_name in [(FEATURES_NUM, HIDDEN_FEATURES_1, \"Layer_1\"),\n",
    "                                                        (HIDDEN_FEATURES_1, HIDDEN_FEATURES_2, \"Layer_2\"),\n",
    "                                                        (HIDDEN_FEATURES_2, CLASSES_NUM, \"Output_layer\")\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a method, which builds a simple MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, layers):\n",
    "    result = x\n",
    "    for weight, bias, scope_name in layers:\n",
    "        with tf.name_scope(scope_name + \"_calculate\"):\n",
    "            result = tf.add(tf.matmul(result, weight), bias)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = mlp(x, layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "with tf.name_scope(\"accuracy_calculation\"):\n",
    "    pred = tf.nn.softmax(logits)\n",
    "    correct_predictions = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'accuracy:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for weight, bias, scope_name in layers:\n",
    "    tf.summary.histogram(scope_name + \"_weights\", weight)\n",
    "    tf.summary.histogram(scope_name + \"_bias\", bias)\n",
    "    \n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "tf.summary.scalar(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_STEP = 3000\n",
    "PRINT_INFO_EVERY = 100\n",
    "TB_PATH = \"/tmp/tensorflow/mnist/logs/mlp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:40<00:00, 73.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.953\n",
      "Test accuracy: 0.891\n",
      "Val accuracy: 0.906\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    summary_merged = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(TB_PATH, sess.graph)\n",
    "    \n",
    "    for step in tqdm(range(MAX_STEP)):\n",
    "        batch = data_sets.train.next_batch(BATCH_SIZE)\n",
    "        result = sess.run([optimizer_step, summary_merged], \n",
    "                            feed_dict={x: batch[0], y: batch[1], learning_rate: 1e-4})\n",
    "        writer.add_summary(result[-1], step)\n",
    "     \n",
    "    batch = data_sets.train.next_batch(BATCH_SIZE)\n",
    "    train_acc = accuracy.eval(feed_dict={x: batch[0], y: batch[1]})\n",
    "    print(\"Train accuracy: {:0.3f}\".format(train_acc))\n",
    "    \n",
    "    batch = data_sets.test.next_batch(BATCH_SIZE)\n",
    "    test_acc = accuracy.eval(feed_dict={x: batch[0], y: batch[1]})\n",
    "    print(\"Test accuracy: {:0.3f}\".format(test_acc))\n",
    "    \n",
    "    batch = data_sets.validation.next_batch(BATCH_SIZE)\n",
    "    val_acc = accuracy.eval(feed_dict={x: batch[0], y: batch[1]})\n",
    "    print(\"Val accuracy: {:0.3f}\".format(val_acc))  \n",
    "    \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py34",
   "language": "python",
   "name": "py34"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
